{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domina Python para LLMs - Parte 2: \n",
    "\n",
    "## Técnicas de manipulación de texto que todo científico de datos debe conocer\n",
    "\n",
    "### 1. Operaciones con listas de tokens\n",
    "\n",
    "#### Manipulación básica de listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación y manipulación básica\n",
    "tokens = ['[START]', 'Hola', 'mundo', '[END]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing para eliminar tokens especiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens sin marcadores: ['Hola', 'mundo']\n"
     ]
    }
   ],
   "source": [
    "tokens_limpios = tokens[1:-1]\n",
    "print(\"Tokens sin marcadores:\", tokens_limpios)\n",
    "# Resultado: Tokens sin marcadores: ['Hola', 'mundo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listas por comprensión para procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens en mayúsculas: ['HOLA', 'MUNDO']\n"
     ]
    }
   ],
   "source": [
    "tokens_mayusculas = [t.upper() for t in tokens_limpios]\n",
    "print(\"Tokens en mayúsculas:\", tokens_mayusculas)\n",
    "# Resultado: Tokens en mayúsculas: ['HOLA', 'MUNDO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrado con condiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens con más de 3 caracteres: ['[START]', 'Hola', 'mundo', '[END]']\n"
     ]
    }
   ],
   "source": [
    "# Filtrado con condiciones\n",
    "tokens_largos = [t for t in tokens if len(t) > 3]\n",
    "print(\"Tokens con más de 3 caracteres:\", tokens_largos)\n",
    "# Resultado: Tokens con más de 3 caracteres: ['[START]', 'mundo', '[END]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Diccionarios para configuración y metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración básica de LLM\n",
    "config = {\n",
    "    'modelo': 'gpt-3.5-turbo',\n",
    "    'temperatura': 0.7,\n",
    "    'max_tokens': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creación y llenado de diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['modelo'] = 'gpt-3.5-turbo'\n",
    "config['temperatura'] = 0.7\n",
    "config['max_tokens'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acceso a valores en un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo seleccionado: gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "# Acceso a valores\n",
    "print(f\"Modelo seleccionado: {config['modelo']}\")\n",
    "# Resultado: Modelo seleccionado: gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diccionarios anidados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionarios anidados\n",
    "config_completo = {\n",
    "    'modelo': {\n",
    "        'nombre': 'gpt-4',\n",
    "        'version': '2024',\n",
    "        'parametros': {\n",
    "            'temperatura': 0.7,\n",
    "            'presencia_penalizacion': 0.1\n",
    "        }\n",
    "    },\n",
    "    'api': {\n",
    "        'timeout': 30,\n",
    "        'reintentos': 3\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperatura configurada: 0.7\n",
      "Reintentos actualizados: 5\n"
     ]
    }
   ],
   "source": [
    "# Acceso a valores anidados\n",
    "temp = config_completo['modelo']['parametros']['temperatura']\n",
    "print(f\"Temperatura configurada: {temp}\")\n",
    "# Resultado: Temperatura configurada: 0.7\n",
    "\n",
    "# Actualización de valores\n",
    "config_completo['api']['reintentos'] = 5\n",
    "print(\"Reintentos actualizados:\", config_completo['api']['reintentos'])\n",
    "# Resultado: Reintentos actualizados: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sets para filtrado eficiente\n",
    "\n",
    "#### Creación de un set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de set de stop words\n",
    "stop_words = {'de', 'la', 'el', 'en', 'y', 'a', 'los', 'las'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens originales: ['el', 'modelo', 'procesa', 'el', 'texto', 'y', 'genera', 'respuestas']\n",
      "Tokens sin stop words: ['modelo', 'procesa', 'texto', 'genera', 'respuestas']\n"
     ]
    }
   ],
   "source": [
    "# Texto de ejemplo\n",
    "texto_tokens = ['el', 'modelo', 'procesa', 'el', 'texto', 'y', 'genera', 'respuestas']\n",
    "\n",
    "# Filtrado de tokens\n",
    "tokens_filtrados = [t for t in texto_tokens if t not in stop_words]\n",
    "print(\"Tokens originales:\", texto_tokens)\n",
    "print(\"Tokens sin stop words:\", tokens_filtrados)\n",
    "# Resultado:\n",
    "# Tokens originales: ['el', 'modelo', 'procesa', 'el', 'texto', 'y', 'genera', 'respuestas']\n",
    "# Tokens sin stop words: ['modelo', 'procesa', 'texto', 'genera', 'respuestas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operaciones con sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las palabras: {'bueno', 'malo', 'pésimo', 'fantástico', 'excelente', 'terrible'}\n"
     ]
    }
   ],
   "source": [
    "# Operaciones con sets\n",
    "palabras_positivas = {'bueno', 'excelente', 'fantástico'}\n",
    "palabras_negativas = {'malo', 'pésimo', 'terrible'}\n",
    "\n",
    "# Unión de sets\n",
    "todas_palabras = palabras_positivas | palabras_negativas\n",
    "print(\"Todas las palabras:\", todas_palabras)\n",
    "# Resultado: Todas las palabras: {'bueno', 'malo', 'excelente', 'fantástico', 'pésimo', 'terrible'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tuplas para datos inmutables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "# Creación de una tupla nombrada para configuración\n",
    "Config = namedtuple('Config', ['modelo', 'temperatura', 'max_tokens'])\n",
    "\n",
    "# Instanciación de la configuración\n",
    "config_default = Config('gpt-4', 0.7, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acceder a los valores de la tupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuración:\n",
      "- Modelo: gpt-4\n",
      "- Temperatura: 0.7\n",
      "- Tokens máx.: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Acceso a valores\n",
    "print(f\"\"\"\n",
    "Configuración:\n",
    "- Modelo: {config_default.modelo}\n",
    "- Temperatura: {config_default.temperatura}\n",
    "- Tokens máx.: {config_default.max_tokens}\n",
    "\"\"\")\n",
    "# Resultado:\n",
    "# Configuración:\n",
    "# - Modelo: gpt-4\n",
    "# - Temperatura: 0.7\n",
    "# - Tokens máx.: 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inmutabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al modificar: can't set attribute\n"
     ]
    }
   ],
   "source": [
    "# Intento de modificación (generará error)\n",
    "try:\n",
    "    config_default.temperatura = 0.8\n",
    "except AttributeError as e:\n",
    "    print(\"Error al modificar:\", str(e))\n",
    "# Resultado: Error al modificar: can't set attribute"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
