{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domina Python para LLMs - Parte 1: \n",
    "\n",
    "## Técnicas de manipulación de texto que todo científico de datos debe conocer\n",
    "\n",
    "### Estructuras de datos optimizadas para texto en Python para LLMs\n",
    "\n",
    "#### Trabajando con strings y su manipulación\n",
    "\n",
    "##### 1. Operaciones básicas con strings\n",
    "\n",
    "**Formateo de strings con f-strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String original: Procesamiento de LLMs\n"
     ]
    }
   ],
   "source": [
    "# Creación de strings\n",
    "texto = \"Procesamiento de LLMs\"\n",
    "print(f\"String original: {texto}\")\n",
    "\n",
    "#Resultado:\n",
    "#String original: Procesamiento de LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funciones aplicadas sobre cadenas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del texto: 21\n"
     ]
    }
   ],
   "source": [
    "# Longitud del string\n",
    "longitud = len(texto)\n",
    "print(f\"Longitud del texto: {longitud}\")\n",
    "# Resultado: Longitud del texto: 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Slicing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer caracter: P\n",
      "Último caracter: s\n",
      "Palabra intermedia: de\n"
     ]
    }
   ],
   "source": [
    "# Acceso a caracteres\n",
    "primer_caracter = texto[0]\n",
    "ultimo_caracter = texto[-1]\n",
    "palabra_de = texto[14:16] \n",
    "\n",
    "print(f\"Primer caracter: {primer_caracter}\")\n",
    "print(f\"Último caracter: {ultimo_caracter}\")\n",
    "print(f\"Palabra intermedia: {palabra_de}\")\n",
    "\n",
    "# Resultado:\n",
    "# Primer caracter: P\n",
    "# Último caracter: s\n",
    "# Palabra intermedia: de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Métodos de limpieza y normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: '   LLMs en producción   '\n",
      "Limpio: 'LLMs en producción'\n"
     ]
    }
   ],
   "source": [
    "# Eliminación de espacios en blanco\n",
    "texto_con_espacios = \"   LLMs en producción   \"\n",
    "texto_limpio = texto_con_espacios.strip()\n",
    "print(f\"Original: '{texto_con_espacios}'\")\n",
    "print(f\"Limpio: '{texto_limpio}'\")\n",
    "# Resultado:\n",
    "# Original: '   LLMs en producción   '\n",
    "# Limpio: 'LLMs en producción'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minúsculas: llms en producción\n",
      "Mayúsculas: LLMS EN PRODUCCIÓN\n"
     ]
    }
   ],
   "source": [
    "# Conversión a minúsculas/mayúsculas\n",
    "texto_lower = texto_limpio.lower()\n",
    "texto_upper = texto_limpio.upper()\n",
    "print(f\"Minúsculas: {texto_lower}\")\n",
    "print(f\"Mayúsculas: {texto_upper}\")\n",
    "# Resultado:\n",
    "# Minúsculas: llms en producción\n",
    "# Mayúsculas: LLMS EN PRODUCCIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Tokenización y división de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Los', 'modelos', 'de', 'lenguaje', 'son', 'fascinantes']\n",
      "Campos: ['modelo', 'temperatura', 'tokens', 'prompt']\n"
     ]
    }
   ],
   "source": [
    "# División básica por espacios\n",
    "texto = \"Los modelos de lenguaje son fascinantes\"\n",
    "tokens = texto.split()\n",
    "print(\"Tokens:\", tokens)\n",
    "# Resultado: Tokens: ['Los', 'modelos', 'de', 'lenguaje', 'son', 'fascinantes']\n",
    "\n",
    "# División por carácter específico\n",
    "texto_csv = \"modelo,temperatura,tokens,prompt\"\n",
    "campos = texto_csv.split(',')\n",
    "print(\"Campos:\", campos)\n",
    "# Resultado: Campos: ['modelo', 'temperatura', 'tokens', 'prompt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros tres: ['a', 'b', 'c:d:e:f']\n"
     ]
    }
   ],
   "source": [
    "# Dividir con límite\n",
    "texto_largo = \"a:b:c:d:e:f\"\n",
    "primeros_tres = texto_largo.split(':', 2)\n",
    "print(\"Primeros tres:\", primeros_tres)\n",
    "# Resultado: Primeros tres: ['a', 'b', 'c:d:e:f']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Construcción de prompts con f-strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sistema: Eres un asistente experto en Python\n",
      "Usuario: ¿Cómo uso list comprehension?\n",
      "Configuración:\n",
      "- Modelo: GPT-4\n",
      "- Temperatura: 0.7\n",
      "- Tokens máximos: 150\n"
     ]
    }
   ],
   "source": [
    "# Prompt simple\n",
    "sistema = \"Eres un asistente experto en Python\"\n",
    "usuario = \"¿Cómo uso list comprehension?\"\n",
    "prompt = f\"Sistema: {sistema}\\nUsuario: {usuario}\"\n",
    "print(prompt)\n",
    "# Resultado:\n",
    "# Sistema: Eres un asistente experto en Python\n",
    "# Usuario: ¿Cómo uso list comprehension?\n",
    "\n",
    "# Prompt con múltiples variables y formato\n",
    "temperatura = 0.7\n",
    "max_tokens = 150\n",
    "prompt_config = f\"\"\"\n",
    "Configuración:\n",
    "- Modelo: GPT-4\n",
    "- Temperatura: {temperatura:.1f}\n",
    "- Tokens máximos: {max_tokens}\n",
    "\"\"\".strip()\n",
    "print(prompt_config)\n",
    "# Resultado:\n",
    "# Configuración:\n",
    "# - Modelo: GPT-4\n",
    "# - Temperatura: 0.7\n",
    "# - Tokens máximos: 150\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
