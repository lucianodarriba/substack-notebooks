{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domina Python para LLMs - Parte 3\n",
    "\n",
    "## Funciones y Lambda: La base del procesamiento en LLMs con Python\n",
    "\n",
    "### La importancia de las funciones bien estructuradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def preprocesar_texto(\n",
    "    texto: str,\n",
    "    stop_words: set = None,\n",
    "    min_longitud: int = 3\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Preprocesa texto para su uso con LLMs.\n",
    "\n",
    "    Args:\n",
    "        texto: Texto a procesar\n",
    "        stop_words: Conjunto de palabras a filtrar\n",
    "        min_longitud: Longitud mínima de tokens a conservar\n",
    "\n",
    "    Returns:\n",
    "        Lista de tokens procesados y filtrados\n",
    "    \"\"\"\n",
    "    tokens = texto.lower().split()\n",
    "    if stop_words:\n",
    "        tokens = [t for t in tokens if t not in stop_words]\n",
    "    return [t for t in tokens if len(t) >= min_longitud]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El poder de las expresiones lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones lambda para transformaciones comunes\n",
    "normalizar = lambda x: x.lower().strip()\n",
    "extraer_entidades = lambda texto: [palabra for palabra in texto.split() if palabra[0].isupper()]\n",
    "calcular_longitud = lambda texto: len(texto.split())\n",
    "\n",
    "# Aplicación práctica\n",
    "textos = ['  Machine Learning es FASCINANTE  ', 'Python para NLP   ']\n",
    "textos_normalizados = list(map(normalizar, textos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinando funciones y operadores funcionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def crear_pipeline_procesamiento(textos: List[str]) -> List[str]:\n",
    "    # Paso 1: Normalización\n",
    "    normalizados = map(normalizar, textos)\n",
    "\n",
    "    # Paso 2: Filtrado de textos vacíos\n",
    "    filtrados = filter(lambda x: len(x) > 0, normalizados)\n",
    "\n",
    "    # Paso 3: Tokenización y limpieza\n",
    "    procesados = [preprocesar_texto(texto) for texto in filtrados]\n",
    "\n",
    "    return list(procesados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejores prácticas para funciones en proyectos de LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_prompt(texto: str, max_longitud: int = 1000) -> str:\n",
    "    \"\"\"\n",
    "    Procesa y valida un prompt para enviar a un LLM.\n",
    "    \"\"\"\n",
    "    if not texto:\n",
    "        raise ValueError(\"El prompt no puede estar vacío\")\n",
    "\n",
    "    texto_procesado = normalizar(texto)\n",
    "\n",
    "    if len(texto_procesado) > max_longitud:\n",
    "        raise ValueError(f\"El prompt excede la longitud máxima de {max_longitud} caracteres\")\n",
    "\n",
    "    return texto_procesado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
