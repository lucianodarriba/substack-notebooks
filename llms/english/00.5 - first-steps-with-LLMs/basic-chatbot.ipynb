{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing the environment\n",
    "\n",
    "First of all, we must import the libraries we will use which, in our case, they are the `OpenAI` module from the `openai` library and the `os` library.\n",
    "\n",
    "Let's recall that the OpenAI API key should be stored in a safe place and never hardcopy it explicitly in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# We load our OpenAI API (in my case, I have it saved\n",
    "# as an environment variable to avoid copying it here explicitly)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "llm = OpenAI(api_key = openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build our chatbot\n",
    "\n",
    "## Defining the expert role\n",
    "Then, we define the kind of expert that our chatbot will be, defining its functionality through a message that we'll later pass on to the language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = {\n",
    "'role': 'developer',\n",
    "'content': \"\"\"\n",
    "    You are a friendly assistant and Python expert.\n",
    "    Answer questions clearly and concisely.\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The chatbot's heart\n",
    "\n",
    "One of the most important parts is the function that takes care of calling the language model itself. By means of this function we can pass to the API and, therefore, to the model, which is what the user is asking for, how does he want to receive the answer, etc. Then, it calls the language model to process his questions and retrieve the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(dev_prompt, user_message):\n",
    "    user_prompt = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "    }\n",
    "    # API call\n",
    "    response = llm.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            dev_prompt,\n",
    "            user_prompt\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Returns the generated text\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main program\n",
    "\n",
    "Once we defined the function that calls the LLM, we create the main program, which will count with a while loop so, after each answer, the program asks for the next question and so we can keep asking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello! I'm your Python assistant. Type 'exit' to end the conversation.\")\n",
    "\n",
    "while True:\n",
    "    user_message = input(\"You: \")\n",
    "    if user_message.lower() == \"exit\":\n",
    "        print(\"Assistant: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    response = get_response(developer_prompt, user_message)\n",
    "    print(f\"Assistant: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First tests\n",
    "\n",
    "When we test the program we noticed that it also answers questions not related to Python.\n",
    "Because of this, we must modify the `developer_prompt` to avoid it to answer things that are not related to its purpose. This is what it's called a *guardrail*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = {\n",
    "    \"role\": \"developer\",\n",
    "    \"content\": \"\"\"\n",
    "        You are a friendly assistant and Python expert.\n",
    "        Answer questions clearly and concisely.\n",
    "        Only answer Python-related questions.\n",
    "        Check if the request relates to any Python concept.\n",
    "        If you receive a question that's not related to Python at all, say that you only know about Python, nothing else.\n",
    "    \"\"\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
