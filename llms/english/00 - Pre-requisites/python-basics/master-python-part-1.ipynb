{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Python for LLMs - Part 1\n",
    "\n",
    "## Text Manipulation Techniques Every Data Scientist Must Know\n",
    "\n",
    "### Optimized data structures for text in Python for LLMs\n",
    "\n",
    "#### Working with strings and their manipulation\n",
    "\n",
    "##### 1. Basic string operations\n",
    "\n",
    "**String formatting with f-strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string: LLMs Processing\n"
     ]
    }
   ],
   "source": [
    "# String creation\n",
    "text = \"LLMs Processing\"\n",
    "print(f\"Original string: {text}\")\n",
    "\n",
    "# Result:\n",
    "# Original string: LLMs Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions applied to strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length: 15\n"
     ]
    }
   ],
   "source": [
    "# String length\n",
    "length = len(text)\n",
    "print(f\"Text length: {length}\")\n",
    "# Result: Text length: 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Indexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First character: L\n",
      "Last character: g\n",
      "Intermediate sub-word: Pro\n"
     ]
    }
   ],
   "source": [
    "# Character access\n",
    "first_character = text[0]\n",
    "last_character = text[-1]\n",
    "word_Pro = text[5:8]\n",
    "\n",
    "print(f\"First character: {first_character}\")\n",
    "print(f\"Last character: {last_character}\")\n",
    "print(f\"Intermediate sub-word: {word_Pro}\")\n",
    "\n",
    "# Result:\n",
    "# First character: L\n",
    "# Last character: g\n",
    "# Intermediate word: Pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Cleaning and normalization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: '   LLMs in production   '\n",
      "Clean: 'LLMs in production'\n"
     ]
    }
   ],
   "source": [
    "# Removing white spaces\n",
    "text_with_spaces= \"   LLMs in production   \"\n",
    "clean_text = text_with_spaces.strip()\n",
    "print(f\"Original: '{text_with_spaces}'\")\n",
    "print(f\"Clean: '{clean_text}'\")\n",
    "# Result:\n",
    "# Original: '   LLMs in production   '\n",
    "# Clean: 'LLMs in production'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercase: llms in production\n",
      "Uppercase: LLMS IN PRODUCTION\n"
     ]
    }
   ],
   "source": [
    "# Conversion to lowercase/uppercase\n",
    "text_lower = clean_text.lower()\n",
    "text_upper = clean_text.upper()\n",
    "print(f\"Lowercase: {text_lower}\")\n",
    "print(f\"Uppercase: {text_upper}\")\n",
    "# Result:\n",
    "# Lowercase: llms in production\n",
    "# Uppercase: LLMS IN PRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tokenization and text division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Language', 'models', 'are', 'fascinating']\n",
      "Fields: ['model', 'temperature', 'tokens', 'prompt']\n"
     ]
    }
   ],
   "source": [
    "# Basic division by spaces\n",
    "text = \"Language models are fascinating\"\n",
    "tokens = text.split()\n",
    "print(\"Tokens:\", tokens)\n",
    "# Result: Tokens: ['Language', 'models', 'are', 'fascinating']\n",
    "\n",
    "# Division by specific character\n",
    "text_csv = \"model,temperature,tokens,prompt\"\n",
    "fields = text_csv.split(',')\n",
    "print(\"Fields:\", fields)\n",
    "# Result: Fields: ['model', 'temperature', 'tokens', 'prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First three: ['a', 'b', 'c:d:e:f']\n"
     ]
    }
   ],
   "source": [
    "# Divide with limit\n",
    "long_text = \"a:b:c:d:e:f\"\n",
    "first_three = long_text.split(':', 2)\n",
    "print(\"First three:\", first_three)\n",
    "# Result: First three: ['a', 'b', 'c:d:e:f']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Prompt construction with f-strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an expert assistant in Python\\\\\\\\nUser: How do I use list comprehension?\n",
      "Configuration:\n",
      "- Model: GPT-4\n",
      "- Temperature: 0.7\n",
      "- Maximum Tokens: 150\n"
     ]
    }
   ],
   "source": [
    "# Simple prompt\n",
    "system = \"You are an expert assistant in Python\"\n",
    "user = \"How do I use list comprehension?\"\n",
    "prompt = f\"System: {system}\\\\\\\\\\\\\\\\nUser: {user}\"\n",
    "print(prompt)\n",
    "# Result:\n",
    "# System: You are an expert assistant in Python\n",
    "# User: How do I use list comprehension?\n",
    "\n",
    "# Prompt with multiple variables and formatting\n",
    "temperature = 0.7\n",
    "max_tokens = 150\n",
    "prompt_config = f\"\"\"\n",
    "Configuration:\n",
    "- Model: GPT-4\n",
    "- Temperature: {temperature:.1f}\n",
    "- Maximum Tokens: {max_tokens}\n",
    "\"\"\".strip()\n",
    "print(prompt_config)\n",
    "# Result:\n",
    "# Configuration:\n",
    "# - Model: GPT-4\n",
    "# - Temperature: 0.7\n",
    "# - Maximum Tokens: 150"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
