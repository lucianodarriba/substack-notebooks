{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Python for LLMs - Part 3\n",
    "\n",
    "## Functions and Lambda: The Foundation of Processing in LLMs with Python\n",
    "\n",
    "### The Importance of Well-Structured Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def preprocess_text(\n",
    "    text: str,\n",
    "    stop_words: set = None,\n",
    "    min_length: int = 3\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Preprocesses text for use with LLMs.\n",
    "\n",
    "    Args:\n",
    "        text: Text to process\n",
    "        stop_words: Set of words to filter\n",
    "        min_length: Minimum token length to keep\n",
    "\n",
    "    Returns:\n",
    "        List of processed and filtered tokens\n",
    "    \"\"\"\n",
    "    tokens = text.lower().split()\n",
    "    if stop_words:\n",
    "        tokens = [t for t in tokens if t not in stop_words]\n",
    "    return [t for t in tokens if len(t) >= min_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Power of Lambda Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda functions for common transformations\n",
    "normalize = lambda x: x.lower().strip()\n",
    "extract_entities = lambda text: [word for word in text.split() if word[0].isupper()]\n",
    "calculate_length = lambda text: len(text.split())\n",
    "\n",
    "# Practical application\n",
    "texts = ['  Machine Learning is FASCINATING  ', 'Python for NLP   ']\n",
    "normalized_texts = list(map(normalize, texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Functions and Functional Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def create_processing_pipeline(texts: List[str]) -> List[str]:\n",
    "    # Step 1: Normalization\n",
    "    normalized = map(normalize, texts)\n",
    "\n",
    "    # Step 2: Filtering empty texts\n",
    "    filtered = filter(lambda x: len(x) > 0, normalized)\n",
    "\n",
    "    # Step 3: Tokenization and cleaning\n",
    "    processed = [preprocess_text(text) for text in filtered]\n",
    "\n",
    "    return list(processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practices for Functions in LLM Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prompt(text: str, max_length: int = 1000) -> str:\n",
    "    \"\"\"\n",
    "    Processes and validates a prompt to send to an LLM.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        raise ValueError(\"The prompt cannot be empty\")\n",
    "\n",
    "    processed_text = normalize(text)\n",
    "\n",
    "    if len(processed_text) > max_length:\n",
    "        raise ValueError(f\"The prompt exceeds the maximum length of {max_length} characters\")\n",
    "\n",
    "    return processed_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
